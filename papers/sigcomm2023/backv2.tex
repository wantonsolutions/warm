\section{Background}

We begin with a brief overview of the RDMA protocol, prior use of
programmable switches in disaggregated settings, and passive remote
memory systems.

\subsection{RDMA protocol}

RDMA was designed as a protocol for accessing remote memory. It
defines a set of zero-copy instructions---known as
\textit{verbs}---that are invoked by clients to read or write memory
physically located on remote servers, typically without kernel
involvement on either end.  When run over Ethernet using the RoCEv2
standard, RDMA NICs located on client and server can cooperate to
implement congestion~\cite{hpcc,dcqcn} and flow control, reliable
delivery, and at-most-once delivery semantics.  Before exchanging
data, RDMA end points establish a queue pair (QP) which defines the
region(s) of memory each is able to access.  Like Internet transport
protocols, RDMA queue pairs provide a configurable set of semantics
depending on the transport mode selected: UDP-like semantics are
provided by Unreliable Datagram (UD) and Unreliable Connections (UC),
while Reliable Connections (RC) are similar to TCP, ensuring reliable,
in-order delivery.  Moreover, reliable connections support so-called
\emph{1-sided} verbs (e.g., read, write, and compare-and-swap) that
are executed autonomously by the remote NIC without any remote CPU
involvement.

The benefits and drawbacks of the various transport modes and
1-vs-2-sided verbs has been a topic of intense debate.  While reliable
connections provide enhanced guarantees, their implementation requires
on-NIC memory, a precious resource, and researchers have observed
scalability bottlenecks due to memory and cache limitations in the
popular Mellanox ConnectX family of RDMA
NICs~\cite{farm,fasst,erpc,litem,design-guidelines}.  Recent work has
shown how to overcome limits in terms of the number of
connections~\cite{storm,flock}, but the ordering guarantees provided
by RC remain restricted to individual queue pairs.  While unreliable
transport modes can deliver superior performance and
scalability~\cite{fasst}, they require the use of 2-sided
verbs---i.e., involvement of a CPU at the memory server---to ensure
ordering, a non-starter for passive disaggregated settings.  Unless
hardware that supports more sophisticated 1-sided verbs~\cite{filemr,rma,star}
becomes available, another approach is required.


%% While
%% host memory can provide better scalability modern NICs have bigger
%% caches with better cache management~\cite{storm}. In the disaggregated
%% setting no memory side CPU exists to manage the state making RC the
%% only option for one sided operations.

%% \todo{connection multiplexing ~\cite{flock}}

%% RDMA

% Remote direct memory access (RDMA) is a network protocol
% which allows NICs to bypass CPUs and access host memory
% directly.  The RDMA protocol consists of a set of verbs
% which abstract remote memory instructions. Instruction
% execution and connection state are entirely managed by the
% NIC which exposes the verbs API to the CPU. The CPU
% registers memory regions for DMA with the NIC and sets up
% connections (Queue Pairs) with a remote RDMA enabled NIC.
% %%
% RDMA connections come in a variety of flavors, each of which
% enables a different set of RDMA verbs and delivary
% guarantee~\cite{herd, erpc, storm}. Unreliable Datagram
% (UD), and Unreliable Connection (UC) operate similar to UDP
% with no reliable delivery or ordering guarantees and a
% restricted set of verbs.  Reliable Connected (RC) operates
% similar to TCP, the NIC manages connection states for each
% QP and ensures reliable in-order delivery by using sequence
% numbers and a go-back-n retransmission protocol.
% %%
% Serious debate exists over which connections to
% use~\cite{storm,cell,herd,faast,farm}, each has advantages
% and disadvantages in terms of NIC resource utilization,
% throughput, and latency. Disaggregated architectures have no
% remote CPU's, in this proposed setting RC is the most
% attractive as it alone enables the use of one-sided verbs
% :\textit{Read}, \textit{Write}, and the atomic \textit{CAS}


%% RDMA Connections
%% RDMA Atomics



\subsection{Programmable Switches}



Most prior proposals for
disaggregation consider rack-scale deployments where
%. They propose a single rack
%with
servers are partitioned into roles: compute, memory, and storage, all of
which are interconnected by a top-of-rack (ToR) switch.  The central
role of the ToR in this architecture has not gone unnoticed, and
researchers have observed that a programmable switch can off-load a
wide variety of traditional operating system
services~\cite{disandapp,mind,netlock,netkv,netchain,netcache}. The
constraints in each case are similar: programmable switches have
limited memory and processing capabilities.  If the computational ask
of the switch is too high packets must be recirculated adding
additional latency and reducing aggregate bandwidth.  Ideal
applications for programmable switches use little memory, require
minimal processing and deliver outsized performance benefit from
centralization.
%, and the billions of operations (in terms of packets)
%that a switch can process per second.
%%

Specifically, prior work has shown that programmable switches are able
to provide rack-scale serialization at low
cost~\cite{eris,no,when-computer,Grant2021InContRes}, manage
locks~\cite{netlock}, and even track the state required to maintain an
RDMA reliable connection~\cite{tea}.  Most relatedly, researchers have
even used a programmable switch to implement a centralized memory
controller for passive remote memory~\cite{mind}.  Their approach is
limited, however, by the resource constraints of the switch.  Inspired
by performance-enhancing TCP proxies of old~\cite{snoop,rfc3135}, we
consider a slightly different design point where the authoritative
state and control logic remain at the end points.  In our approach,
the ToR simply observes and, at times, selectively modifies RDMA
packets~\cite{switchml,Grant2021InContRes} in-flight to improve
performance while preserving the semantics of the underlying RDMA
connections.

%% , and . These properties make a top-of-rack
%% programable switch ideal for managing remote memory as it can guard
%% access, maintain connections, and provide serialization primitives for
%% all clients.

%\todo{RDMA middlebox (find citaitons ~\cite{mind,switchml})}

\subsection{Disaggregated Memory}

Memory disaggregation separates primary storage from the CPU
by a fast network. The question \textit{how to present
memory over the network to an application?} is still open,
and a spectrum of system designs currently exist.
Transparent systems present far memory to the application as
if it were local. Virtual memory enables paging systems to
keep a cache of local pages, and swap in and out
transparently on page faults ~\cite{infiniswap, leap,
fastswap}.  Some have argued that page granularity is too
course and built upon an incoherent caching
layer~\cite{kona, legoos}.  In both cases transparency
incurs a performance cost as remote accesses cannot be
optimized for by the running application.
%%
Alternatively applications can access remote memory
explicitly with an API similar to an RPC
call~\cite{aifm,reigons,clover,sherman,faast}. Explicit
access allows for optimized remote requests. They can be
batched, scheduled, and managed by libraries and run times. 
%%
Whether explicit or transparent sharing is expensive, at the
time of writing no transparent system supports shared memory
-- the cost of cache coherence is prohibitively high in
terms of bandwidth and latency. Explicit cases are more
promising for sharing as they allow application developers
to acquire locks, and for libraries to make use of
optimistically concurrent datastructures.
