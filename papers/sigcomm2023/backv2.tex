\section{Background}

\subsection{Disaggregated Memory}

Memory disaggregation separates primary storage from the CPU
by a fast network. The question \textit{how to present
memory over the network to an application?} is still open,
and a spectrum of system designs currently exist.
Transparent systems present far memory to the application as
if it were local. Virtual memory enables paging systems to
keep a cache of local pages, and swap in and out
transparently on page faults ~\cite{infiniswap, leap,
fastswap}.  Some have argued that page granularity is too
course and built upon an incoherent caching
layer~\cite{kona, legoos}.  In both cases transparency
incurs a performance cost as remote accesses cannot be
optimized for by the running application.
%%
Alternatively applications can access remote memory
explicitly with an API similar to an RPC
call~\cite{aifm,reigons,clover,sherman,faast}. Explicit
access allows for optimized remote requests. They can be
batched, scheduled, and managed by libraries and runtimes. 
%%
Whether explicit or transparent sharing is expensive, at the
time of writing no transparent system supports shared memory
-- the cost of cache coherence is prohibitively high in
terms of bandwidth and latency. Explicit cases are more
promising for sharing as they allow application developers
to acquire locks, and for libraries to make use of
optimistically concurrent datastrcutrues.

\subsection{RDMA protocol}

RDMA provides an interface for accessing remote memory. It
provides a set of zero copy instructions (\textit{verbs})
which are initiated by a client cpu. NICs manage the entire
network stack including control flow, reliable delivery, and
at most once semantics. The guarantees RDMA provides are
configurable -- connection's UDP like semantics are provided
by Unreliable Datagram (UD) and Unreliable Connections (UC),
while Reliable Connections (RC) at similar to TCP, ensuring
in order delivery, and enabling RDMA's one-sided operations
Read, Write, and Compare and Swap (CAS).

Which connections to use is an intense topic for debate.
Reliable connections use NIC memory, a precious resource,
and projects designed using Mellanox CX3-CX5 noted that RC
bottlenecked scalability due to memory and cache
limitations~\cite{farm,faast,erpc,litem,design-guidelines}.
While host memory can provide better scalability modern NICs
have bigger caches with better cache
management~\cite{storm}. In the disaggregated setting no
memory side CPU exists to manage the state making RC the
only option for one sided operations.

\todo{connection multiplexing ~\cite{flock}}
\todo{RDMA middlebox (find citaitons ~\cite{mind,switchml})}

%% RDMA

% Remote direct memory access (RDMA) is a network protocol
% which allows NICs to bypass CPUs and access host memory
% directly.  The RDMA protocol consists of a set of verbs
% which abstract remote memory instructions. Instruction
% execution and connection state are entirely managed by the
% NIC which exposes the verbs API to the CPU. The CPU
% registers memory regions for DMA with the NIC and sets up
% connections (Queue Pairs) with a remote RDMA enabled NIC.
% %%
% RDMA connections come in a variety of flavors, each of which
% enables a different set of RDMA verbs and delivary
% guarantee~\cite{herd, erpc, storm}. Unreliable Datagram
% (UD), and Unreliable Connection (UC) operate similar to UDP
% with no reliable delivery or ordering guarantees and a
% restricted set of verbs.  Reliable Connected (RC) operates
% similar to TCP, the NIC manages connection states for each
% QP and ensures reliable in-order delivery by using sequence
% numbers and a go-back-n retransmission protocol.
% %%
% Serious debate exists over which connections to
% use~\cite{storm,cell,herd,faast,farm}, each has advantages
% and disadvantages in terms of NIC resource utilization,
% throughput, and latency. Disaggregated architectures have no
% remote CPU's, in this proposed setting RC is the most
% attractive as it alone enables the use of one-sided verbs
% :\textit{Read}, \textit{Write}, and the atomic \textit{CAS}
.


%% RDMA Connections
%% RDMA Atomics

\subsection{Programmable Switches} Most proposals for
disaggregation are at rack-scale. They propose a single rack
with servers partitioned into roles: compute, memory, and
storage, each of which is interconnected by a TOR.  The TOR
is central in this architecture, a fact which has not gone
unnoticed by system designers who argue that a programmable
switch can facilitate remote memory apis, and OS
functionality~\cite{disandapp,mind}. 
%%
Literature on offloading OS, and service level functionality
to programmable switches is
plentiful~\cite{netlock,netkv,netchain,netcache}. The
constraints in each case are similar, switches have limited
memory, and processing capabilities, if the computational
ask of the switch is too high packets must be recirculated
adding additional latency, and reducing aggregate bandwidth.
Ideal applications for programmable switches use little
memory, require little processing and enable a huge
performance benefit from centralization, and the billions of
operations (in terms of packets) that a switch can process
per second.
%%
Prior work has shown that programmable switches are able to
manage locks~\cite{netlock}, track the state required to
maintain an RDMA reliable connection~\cite{tea}, and provide
rack scale serialization at low
cost~\cite{eris,no,when-computer}. These properties make a
top-of-rack programable switch ideal for managing remote
memory as it can guard access, maintain connections, and
provide serialization primitives for all clients.
