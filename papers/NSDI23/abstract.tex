\begin{abstract}

Effectively sharing passive remote memory remains an open problem.
While emerging standards like CXL promise cache-coherent memory
pooling, the spec-compliant hardware is not yet commercially
avaialble and its feasability at scale remains unproven.
%Fundamentally, any
%design must choose a serialization point and then ensure in-order
%communication and operation from that point on.
%Most performant
As a result, existing RDMA-based systems employ optimistic concurrency
approaches that defer serialization to the remote memory server and
rely upon heavyweight RDMA atomics to ensure consistency.
Unfortunately, atomic operations scale poorly causing these approaches
to degrade rapidly under contention.

We present \sword, an alternative approach that leverages the de-facto
serialization point in rack-scale disaggregated systems---the
top-of-rack switch---to \emph{transparently} resolve data races in
flight.  In cases where \sword\ has sufficient resources to interpose
on all requests, it can remove heavyweight atomic verbs and replace
them with simple write operations, avoiding the hardware performance
bottleneck entirely.  More generally, however, it can safely operate
on only a subset of the requests, dynamically adjusting contending
requests to avoid expensive client-based resolution in those cases.
Under a 50:50 read-write workload, our P4-based prototype
dramatically improves the performance of Clover, a state-of-the-art
disaggregated key-value store: throughput rises by nearly $35\times$,
tail latency drops by over $300\times$, and bandwidth usage drops by a
factor of 16.  %Further, by removing RDMA atomics, we avoid
%hardware-imposed scalability limits.
%of $\approx$2.7 MOP/s per queue pair.
  
%% Disaggregating memory from compute incurs extreme latency
%% penalties. These penalties are multiplied when remote memory is shared
%% and contended for. State of the art approaches for mitigating the cost
%% of contention use mostly lock-less data structures for accessing and
%% modifying remote memory with common case O(1) operations.
%% Unfortunately in the face of even modestly contended resources
%% opportunistic algorithms incur extreme performance degradation due to
%% multiple round trip times, and expensive atomic memory operations such
%% as compare and swap.

%% We present \sword, an in-network serializer

%% In this work we make the observation that all memory operations in a
%% rack scale disaggregation system pass through a centralized switch
%% which must serialize all remote memory accesses on the wire. We use
%% this implicit serialization to arbitrate access to rack scale
%% memory. We use Clover (a state of the art disaggregated key value
%% store) to show that our approach removes all conflict, and can provide
%% serialization which allows for the removal of expensive atomic locking
%% operations.

\end{abstract}
